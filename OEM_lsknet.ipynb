{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTGkOTdOpBll"
   },
   "source": [
    "# OpenEarhMap Semantinc Segmentation\n",
    "\n",
    "This demo code demonstrates training and testing of UNet-EfficientNet-B4 for the OpenEarthMap dataset (https://open-earth-map.org/). This demo code is based on the work from the \"segmentation_models.pytorch\" repository by qubvel, available at: https://github.com/qubvel/segmentation_models.pytorch. We extend our sincere appreciation to the original author for their invaluable contributions to the field of semantic segmentation and for providing this open-source implementation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWiUctcOpBlo"
   },
   "source": [
    "### Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/open-earth-map\n",
      "\u001b[0m\u001b[01;34mGeoSeg\u001b[0m/           OpenEarthMap.zip   deep_lab.ipynb  \u001b[01;34moutputs\u001b[0m/      xBD.zip\n",
      "\u001b[01;34mLSKNet\u001b[0m/           \u001b[01;34mOpenEarthMap_old\u001b[0m/  \u001b[01;34mdemo\u001b[0m/           \u001b[01;34mpredictions\u001b[0m/  \u001b[01;34mxBD_old\u001b[0m/\n",
      "OEM_demo.ipynb    \u001b[01;34mSFA-Net\u001b[0m/           example.png     \u001b[01;34msource\u001b[0m/\n",
      "OEM_lsknet.ipynb  \u001b[01;34maerial-former\u001b[0m/     \u001b[01;34mmodels\u001b[0m/         \u001b[01;34mtest\u001b[0m/\n",
      "\u001b[01;34mOpenEarthMap\u001b[0m/     compile_xbd.py     oem.ipynb       \u001b[01;34mxBD\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%cd open-earth-map/\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gQdFTlpypBlp",
    "outputId": "755dab4f-711e-4438-c42c-a1a5cbbeb130"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (2.3.1+cu121)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch) (1.13.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.11/site-packages (from torch) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Collecting rasterio\n",
      "  Using cached rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting affine (from rasterio)\n",
      "  Using cached affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs in /opt/conda/lib/python3.11/site-packages (from rasterio) (23.2.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from rasterio) (2024.7.4)\n",
      "Requirement already satisfied: click>=4.0 in /opt/conda/lib/python3.11/site-packages (from rasterio) (8.1.7)\n",
      "Collecting cligj>=0.5 (from rasterio)\n",
      "  Using cached cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: numpy>=1.24 in /opt/conda/lib/python3.11/site-packages (from rasterio) (1.26.4)\n",
      "Collecting click-plugins (from rasterio)\n",
      "  Using cached click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.11/site-packages (from rasterio) (3.1.2)\n",
      "Using cached rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
      "Using cached cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
      "Using cached affine-2.4.0-py3-none-any.whl (15 kB)\n",
      "Using cached click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
      "Installing collected packages: cligj, click-plugins, affine, rasterio\n",
      "Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.4.3\n",
      "Collecting pretrainedmodels\n",
      "  Using cached pretrainedmodels-0.7.4-py3-none-any.whl\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from pretrainedmodels) (2.3.1+cu121)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.11/site-packages (from pretrainedmodels) (0.18.1+cu121)\n",
      "Collecting munch (from pretrainedmodels)\n",
      "  Using cached munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from pretrainedmodels) (4.66.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch->pretrainedmodels) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch->pretrainedmodels) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->pretrainedmodels) (1.13.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->pretrainedmodels) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->pretrainedmodels) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->pretrainedmodels) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->pretrainedmodels) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->pretrainedmodels) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->pretrainedmodels) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch->pretrainedmodels) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch->pretrainedmodels) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch->pretrainedmodels) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch->pretrainedmodels) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch->pretrainedmodels) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch->pretrainedmodels) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch->pretrainedmodels) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->pretrainedmodels) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.11/site-packages (from torch->pretrainedmodels) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->pretrainedmodels) (12.5.82)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from torchvision->pretrainedmodels) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision->pretrainedmodels) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->pretrainedmodels) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->pretrainedmodels) (1.3.0)\n",
      "Using cached munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
      "Installing collected packages: munch, pretrainedmodels\n",
      "Successfully installed munch-4.0.0 pretrainedmodels-0.7.4\n",
      "Collecting efficientnet_pytorch\n",
      "  Using cached efficientnet_pytorch-0.7.1-py3-none-any.whl\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from efficientnet_pytorch) (2.3.1+cu121)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet_pytorch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet_pytorch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet_pytorch) (1.13.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet_pytorch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet_pytorch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet_pytorch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet_pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet_pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet_pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet_pytorch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet_pytorch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet_pytorch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet_pytorch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet_pytorch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet_pytorch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet_pytorch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet_pytorch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.11/site-packages (from torch->efficientnet_pytorch) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->efficientnet_pytorch) (12.5.82)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->efficientnet_pytorch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\n",
      "Installing collected packages: efficientnet_pytorch\n",
      "Successfully installed efficientnet_pytorch-0.7.1\n",
      "Collecting timm\n",
      "  Using cached timm-1.0.14-py3-none-any.whl.metadata (50 kB)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from timm) (2.3.1+cu121)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.11/site-packages (from timm) (0.18.1+cu121)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from timm) (6.0.1)\n",
      "Collecting huggingface_hub (from timm)\n",
      "  Using cached huggingface_hub-0.27.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting safetensors (from timm)\n",
      "  Using cached safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->timm) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->timm) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->timm) (24.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->timm) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->timm) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub->timm) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->timm) (1.13.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->timm) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.11/site-packages (from torch->timm) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->timm) (12.5.82)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from torchvision->timm) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision->timm) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->timm) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->timm) (1.3.0)\n",
      "Using cached timm-1.0.14-py3-none-any.whl (2.4 MB)\n",
      "Using cached huggingface_hub-0.27.1-py3-none-any.whl (450 kB)\n",
      "Using cached safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (461 kB)\n",
      "Installing collected packages: safetensors, huggingface_hub, timm\n",
      "Successfully installed huggingface_hub-0.27.1 safetensors-0.5.2 timm-1.0.14\n",
      "Collecting albumentations\n",
      "  Downloading albumentations-2.0.1-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /opt/conda/lib/python3.11/site-packages (from albumentations) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /opt/conda/lib/python3.11/site-packages (from albumentations) (1.14.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.11/site-packages (from albumentations) (6.0.1)\n",
      "Collecting pydantic>=2.9.2 (from albumentations)\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting albucore==0.0.23 (from albumentations)\n",
      "  Using cached albucore-0.0.23-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting opencv-python-headless>=4.9.0.80 (from albumentations)\n",
      "  Using cached opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting stringzilla>=3.10.4 (from albucore==0.0.23->albumentations)\n",
      "  Using cached stringzilla-3.11.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (80 kB)\n",
      "Collecting simsimd>=5.9.2 (from albucore==0.0.23->albumentations)\n",
      "  Using cached simsimd-6.2.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (66 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.11/site-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic>=2.9.2->albumentations)\n",
      "  Using cached pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/conda/lib/python3.11/site-packages (from pydantic>=2.9.2->albumentations) (4.12.2)\n",
      "Downloading albumentations-2.0.1-py3-none-any.whl (276 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.8/276.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached albucore-0.0.23-py3-none-any.whl (14 kB)\n",
      "Using cached opencv_python_headless-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50.0 MB)\n",
      "Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.7/431.7 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Using cached simsimd-6.2.1-cp311-cp311-manylinux_2_28_x86_64.whl (632 kB)\n",
      "Using cached stringzilla-3.11.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (307 kB)\n",
      "Installing collected packages: stringzilla, simsimd, pydantic-core, opencv-python-headless, pydantic, albucore, albumentations\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.20.1\n",
      "    Uninstalling pydantic_core-2.20.1:\n",
      "      Successfully uninstalled pydantic_core-2.20.1\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.8.2\n",
      "    Uninstalling pydantic-2.8.2:\n",
      "      Successfully uninstalled pydantic-2.8.2\n",
      "Successfully installed albucore-0.0.23 albumentations-2.0.1 opencv-python-headless-4.11.0.86 pydantic-2.10.6 pydantic-core-2.27.2 simsimd-6.2.1 stringzilla-3.11.3\n",
      "Collecting segmentation_models_pytorch\n",
      "  Using cached segmentation_models_pytorch-0.4.0-py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: efficientnet-pytorch>=0.6.1 in /opt/conda/lib/python3.11/site-packages (from segmentation_models_pytorch) (0.7.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.24 in /opt/conda/lib/python3.11/site-packages (from segmentation_models_pytorch) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /opt/conda/lib/python3.11/site-packages (from segmentation_models_pytorch) (1.26.4)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.11/site-packages (from segmentation_models_pytorch) (10.4.0)\n",
      "Requirement already satisfied: pretrainedmodels>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from segmentation_models_pytorch) (0.7.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from segmentation_models_pytorch) (1.16.0)\n",
      "Requirement already satisfied: timm>=0.9 in /opt/conda/lib/python3.11/site-packages (from segmentation_models_pytorch) (1.0.14)\n",
      "Requirement already satisfied: torch>=1.8 in /opt/conda/lib/python3.11/site-packages (from segmentation_models_pytorch) (2.3.1+cu121)\n",
      "Requirement already satisfied: torchvision>=0.9 in /opt/conda/lib/python3.11/site-packages (from segmentation_models_pytorch) (0.18.1+cu121)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from segmentation_models_pytorch) (4.66.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.24->segmentation_models_pytorch) (4.12.2)\n",
      "Requirement already satisfied: munch in /opt/conda/lib/python3.11/site-packages (from pretrainedmodels>=0.7.1->segmentation_models_pytorch) (4.0.0)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.11/site-packages (from timm>=0.9->segmentation_models_pytorch) (0.5.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->segmentation_models_pytorch) (1.13.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->segmentation_models_pytorch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->segmentation_models_pytorch) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->segmentation_models_pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->segmentation_models_pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->segmentation_models_pytorch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->segmentation_models_pytorch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->segmentation_models_pytorch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->segmentation_models_pytorch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->segmentation_models_pytorch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->segmentation_models_pytorch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->segmentation_models_pytorch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->segmentation_models_pytorch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->segmentation_models_pytorch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.8->segmentation_models_pytorch) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8->segmentation_models_pytorch) (12.5.82)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.8->segmentation_models_pytorch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.24->segmentation_models_pytorch) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.8->segmentation_models_pytorch) (1.3.0)\n",
      "Using cached segmentation_models_pytorch-0.4.0-py3-none-any.whl (121 kB)\n",
      "Installing collected packages: segmentation_models_pytorch\n",
      "Successfully installed segmentation_models_pytorch-0.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install rasterio\n",
    "!pip install pretrainedmodels\n",
    "!pip install efficientnet_pytorch\n",
    "!pip install timm\n",
    "!pip install albumentations\n",
    "!pip install segmentation_models_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openmim\n",
      "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: Click in /opt/conda/lib/python3.11/site-packages (from openmim) (8.1.7)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.11/site-packages (from openmim) (0.4.6)\n",
      "Collecting model-index (from openmim)\n",
      "  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting opendatalab (from openmim)\n",
      "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from openmim) (2.2.2)\n",
      "Requirement already satisfied: pip>=19.3 in /opt/conda/lib/python3.11/site-packages (from openmim) (24.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from openmim) (2.32.3)\n",
      "Collecting rich (from openmim)\n",
      "  Using cached rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting tabulate (from openmim)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from model-index->openmim) (6.0.1)\n",
      "Collecting markdown (from model-index->openmim)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting ordered-set (from model-index->openmim)\n",
      "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pycryptodome (from opendatalab->openmim)\n",
      "  Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from opendatalab->openmim) (4.66.4)\n",
      "Collecting openxlab (from opendatalab->openmim)\n",
      "  Downloading openxlab-0.1.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->openmim) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->openmim) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->openmim) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->openmim) (2024.7.4)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/conda/lib/python3.11/site-packages (from pandas->openmim) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->openmim) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->openmim) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas->openmim) (2024.1)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->openmim)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.11/site-packages (from rich->openmim) (2.18.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->openmim)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->openmim) (1.16.0)\n",
      "Collecting filelock~=3.14.0 (from openxlab->opendatalab->openmim)\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim)\n",
      "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: packaging~=24.0 in /opt/conda/lib/python3.11/site-packages (from openxlab->opendatalab->openmim) (24.1)\n",
      "Collecting pytz>=2020.1 (from pandas->openmim)\n",
      "  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting requests (from openmim)\n",
      "  Downloading requests-2.28.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting rich (from openmim)\n",
      "  Downloading rich-13.4.2-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting setuptools~=60.2.0 (from openxlab->opendatalab->openmim)\n",
      "  Downloading setuptools-60.2.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tqdm (from opendatalab->openmim)\n",
      "  Downloading tqdm-4.65.2-py3-none-any.whl.metadata (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting urllib3<1.27,>=1.21.1 (from requests->openmim)\n",
      "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting crcmod>=1.7 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
      "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting aliyun-python-sdk-kms>=2.4.1 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
      "  Downloading aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting aliyun-python-sdk-core>=2.13.12 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
      "  Downloading aliyun-python-sdk-core-2.16.0.tar.gz (449 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.6/449.6 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: cryptography>=3.0.0 in /opt/conda/lib/python3.11/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (42.0.8)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.11/site-packages (from cryptography>=3.0.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (1.16.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=3.0.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (2.22)\n",
      "Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
      "Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading openxlab-0.1.2-py3-none-any.whl (311 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.5/311.5 kB\u001b[0m \u001b[31m119.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.4.2-py3-none-any.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2023.4-py2.py3-none-any.whl (506 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.5/506.5 kB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.65.2-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
      "Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m111.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading setuptools-60.2.0-py3-none-any.whl (953 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.5/99.5 kB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: oss2, aliyun-python-sdk-core, crcmod\n",
      "  Building wheel for oss2 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for oss2: filename=oss2-2.17.0-py3-none-any.whl size=112373 sha256=47891c158dccf0f0a658e36683ddb2ef8275cceab29575ba51dfd394703b4930\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/42/79/aa/3671e313c27de35211d345d7a9d8ccb7dde515cf05edba75df\n",
      "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.16.0-py3-none-any.whl size=535318 sha256=20e3cc5cbb954801f10ce8951c60d0973b893496373a0333cfe87296490aeb16\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/2b/9a/95/60f111d2a488c5f7f7ed2a96ce407ea57ec7393ddfdec8c956\n",
      "  Building wheel for crcmod (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for crcmod: filename=crcmod-1.7-cp311-cp311-linux_x86_64.whl size=23535 sha256=9ab9529ae03885fa79267d72692886e234afe025dd19ababb01eb546400f110d\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/23/94/7a/8cb7d14597e6395ce969933f01aed9ea8fa5f5b4d4c8a61e99\n",
      "Successfully built oss2 aliyun-python-sdk-core crcmod\n",
      "Installing collected packages: pytz, crcmod, urllib3, tqdm, tabulate, setuptools, pycryptodome, ordered-set, mdurl, markdown, jmespath, filelock, requests, model-index, markdown-it-py, rich, aliyun-python-sdk-core, aliyun-python-sdk-kms, oss2, openxlab, opendatalab, openmim\n",
      "  Attempting uninstall: pytz\n",
      "    Found existing installation: pytz 2024.1\n",
      "    Uninstalling pytz-2024.1:\n",
      "      Successfully uninstalled pytz-2024.1\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.2\n",
      "    Uninstalling urllib3-2.2.2:\n",
      "      Successfully uninstalled urllib3-2.2.2\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.4\n",
      "    Uninstalling tqdm-4.66.4:\n",
      "      Successfully uninstalled tqdm-4.66.4\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 71.0.4\n",
      "    Uninstalling setuptools-71.0.4:\n",
      "      Successfully uninstalled setuptools-71.0.4\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.13.1\n",
      "    Uninstalling filelock-3.13.1:\n",
      "      Successfully uninstalled filelock-3.13.1\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.3\n",
      "    Uninstalling requests-2.32.3:\n",
      "      Successfully uninstalled requests-2.32.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyterlab-server 2.27.3 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aliyun-python-sdk-core-2.16.0 aliyun-python-sdk-kms-2.16.5 crcmod-1.7 filelock-3.14.0 jmespath-0.10.0 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 model-index-0.1.11 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.1.2 ordered-set-4.1.0 oss2-2.17.0 pycryptodome-3.21.0 pytz-2023.4 requests-2.28.2 rich-13.4.2 setuptools-60.2.0 tabulate-0.9.0 tqdm-4.65.2 urllib3-1.26.20\n",
      "Looking in links: https://download.openmmlab.com/mmcv/dist/cu121/torch2.3.0/index.html\n",
      "Collecting mmcv-full\n",
      "  Downloading mmcv-full-1.7.2.tar.gz (607 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m607.9/607.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[18 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-gel6ioiw/mmcv-full_0319e6fa36f14b3686fe8087d2e3295d/setup.py\", line 572, in <module>\n",
      "  \u001b[31m   \u001b[0m     ext_modules=get_extensions(),\n",
      "  \u001b[31m   \u001b[0m                 ^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-gel6ioiw/mmcv-full_0319e6fa36f14b3686fe8087d2e3295d/setup.py\", line 474, in get_extensions\n",
      "  \u001b[31m   \u001b[0m     ext_ops = extension(\n",
      "  \u001b[31m   \u001b[0m               ^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 1077, in CUDAExtension\n",
      "  \u001b[31m   \u001b[0m     library_dirs += library_paths(cuda=True)\n",
      "  \u001b[31m   \u001b[0m                     ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 1204, in library_paths\n",
      "  \u001b[31m   \u001b[0m     if (not os.path.exists(_join_cuda_home(lib_dir)) and\n",
      "  \u001b[31m   \u001b[0m                            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 2419, in _join_cuda_home\n",
      "  \u001b[31m   \u001b[0m     raise OSError('CUDA_HOME environment variable is not set. '\n",
      "  \u001b[31m   \u001b[0m OSError: CUDA_HOME environment variable is not set. Please set it to your CUDA install root.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\u001b[?25hLooking in links: https://download.openmmlab.com/mmcv/dist/cu121/torch2.3.0/index.html\n",
      "Collecting mmdet\n",
      "  Downloading mmdet-3.3.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.11/site-packages (from mmdet) (3.9.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from mmdet) (1.26.4)\n",
      "Collecting pycocotools (from mmdet)\n",
      "  Downloading pycocotools-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from mmdet) (1.14.0)\n",
      "Collecting shapely (from mmdet)\n",
      "  Downloading shapely-2.0.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.11/site-packages (from mmdet) (1.16.0)\n",
      "Collecting terminaltables (from mmdet)\n",
      "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from mmdet) (4.65.2)\n",
      "Collecting mmcv<2.2.0,>=2.0.0rc4 (from mmdet)\n",
      "  Downloading mmcv-2.1.0.tar.gz (471 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.4/471.4 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[18 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-j0gp1e7g/mmcv_c6d9538ed1c24fb58a0dc3ebf8731f10/setup.py\", line 477, in <module>\n",
      "  \u001b[31m   \u001b[0m     ext_modules=get_extensions(),\n",
      "  \u001b[31m   \u001b[0m                 ^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-j0gp1e7g/mmcv_c6d9538ed1c24fb58a0dc3ebf8731f10/setup.py\", line 434, in get_extensions\n",
      "  \u001b[31m   \u001b[0m     ext_ops = extension(\n",
      "  \u001b[31m   \u001b[0m               ^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 1077, in CUDAExtension\n",
      "  \u001b[31m   \u001b[0m     library_dirs += library_paths(cuda=True)\n",
      "  \u001b[31m   \u001b[0m                     ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 1204, in library_paths\n",
      "  \u001b[31m   \u001b[0m     if (not os.path.exists(_join_cuda_home(lib_dir)) and\n",
      "  \u001b[31m   \u001b[0m                            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 2419, in _join_cuda_home\n",
      "  \u001b[31m   \u001b[0m     raise OSError('CUDA_HOME environment variable is not set. '\n",
      "  \u001b[31m   \u001b[0m OSError: CUDA_HOME environment variable is not set. Please set it to your CUDA install root.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\u001b[?25hCollecting mmrotate\n",
      "  Downloading mmrotate-0.3.4-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting e2cnn (from mmrotate)\n",
      "  Downloading e2cnn-0.2.3-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.11/site-packages (from mmrotate) (3.9.1)\n",
      "Collecting mmcv-full (from mmrotate)\n",
      "  Using cached mmcv-full-1.7.2.tar.gz (607 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[18 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-5sc2x8y0/mmcv-full_2dcb1aa5d4084500bc10b428d8a2a2a6/setup.py\", line 572, in <module>\n",
      "  \u001b[31m   \u001b[0m     ext_modules=get_extensions(),\n",
      "  \u001b[31m   \u001b[0m                 ^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-5sc2x8y0/mmcv-full_2dcb1aa5d4084500bc10b428d8a2a2a6/setup.py\", line 474, in get_extensions\n",
      "  \u001b[31m   \u001b[0m     ext_ops = extension(\n",
      "  \u001b[31m   \u001b[0m               ^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 1077, in CUDAExtension\n",
      "  \u001b[31m   \u001b[0m     library_dirs += library_paths(cuda=True)\n",
      "  \u001b[31m   \u001b[0m                     ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 1204, in library_paths\n",
      "  \u001b[31m   \u001b[0m     if (not os.path.exists(_join_cuda_home(lib_dir)) and\n",
      "  \u001b[31m   \u001b[0m                            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/opt/conda/lib/python3.11/site-packages/torch/utils/cpp_extension.py\", line 2419, in _join_cuda_home\n",
      "  \u001b[31m   \u001b[0m     raise OSError('CUDA_HOME environment variable is not set. '\n",
      "  \u001b[31m   \u001b[0m OSError: CUDA_HOME environment variable is not set. Please set it to your CUDA install root.\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# MM Rotate Installation\n",
    "\n",
    "!pip install -U openmim\n",
    "!mim install mmcv-full\n",
    "!mim install mmdet\n",
    "!pip install mmrotate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4elx5iipBlq"
   },
   "source": [
    "### Import\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zhMDpFqZpBlr"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import segmentation_models_pytorch as smp\n",
    "import source\n",
    "import glob\n",
    "import torchvision.transforms.functional as TF\n",
    "import math\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mmcv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlsknet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSKNet\n\u001b[1;32m      4\u001b[0m smp\u001b[38;5;241m.\u001b[39mencoders\u001b[38;5;241m.\u001b[39mencoders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlsk_net\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder\u001b[39m\u001b[38;5;124m\"\u001b[39m: LSKNet,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     },\n\u001b[1;32m     20\u001b[0m }\n",
      "File \u001b[0;32m~/open-earth-map/models/lsknet.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pair \u001b[38;5;28;01mas\u001b[39;00m to_2tuple\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmmcv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mweight_init\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constant_init, normal_init, trunc_normal_init\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbuilder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ROTATED_BACKBONES\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtimm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DropPath, to_2tuple, trunc_normal_\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mmcv'"
     ]
    }
   ],
   "source": [
    "from models.lsknet import LSKNet\n",
    "\n",
    "smp.encoders.encoders[\"lsk_net\"] = {\n",
    "    \"encoder\": LSKNet,\n",
    "    \"params\": {\n",
    "        \"img_size\": 224,\n",
    "        \"in_chans\": 3,\n",
    "        \"embed_dims\": [64, 128, 256, 512],\n",
    "        \"mlp_ratios\": [8, 8, 4, 4],\n",
    "        \"drop_rate\": 0.0,\n",
    "        \"drop_path_rate\": 0.0,\n",
    "        \"norm_layer\": partial(nn.LayerNorm, eps=1e-6),\n",
    "        \"depths\": [3, 4, 6, 3],\n",
    "        \"num_stages\": 4,\n",
    "        \"pretrained\": None,\n",
    "        \"init_cfg\": None,\n",
    "        \"norm_cfg\": None,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Os768d4EpBlr"
   },
   "source": [
    "### Define main parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fOj5_N4apBlr",
    "outputId": "fcfc3a93-3030-4614-ecdf-ba54ca866b6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs   : 5\n",
      "Number of classes  : 9\n",
      "Batch size         : 4\n",
      "Device             : cuda\n"
     ]
    }
   ],
   "source": [
    "OEM_ROOT = \"./demo/\"\n",
    "OEM_DATA_DIR = \"OpenEarthMap/\"\n",
    "TRAIN_LIST = OEM_DATA_DIR+\"train.txt\"\n",
    "VAL_LIST = OEM_DATA_DIR+\"val.txt\"\n",
    "TEST_LIST = OEM_DATA_DIR+\"test.txt\"\n",
    "WEIGHT_DIR = OEM_ROOT+\"weight\" # path to save weights\n",
    "OUT_DIR = OEM_ROOT+\"result/\" # path to save prediction images\n",
    "os.makedirs(WEIGHT_DIR, exist_ok=True)\n",
    "\n",
    "seed = 0\n",
    "learning_rate = 0.0001\n",
    "batch_size = 4\n",
    "n_epochs = 5\n",
    "classes = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "n_classes = len(classes)+1\n",
    "classes_wt = np.ones([n_classes], dtype=np.float32)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(\"Number of epochs   :\", n_epochs)\n",
    "print(\"Number of classes  :\", n_classes)\n",
    "print(\"Batch size         :\", batch_size)\n",
    "print(\"Device             :\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UCETH4-PpBls"
   },
   "source": [
    "### Prepare training and validation file lists\n",
    "\n",
    "In this demo for Google Colab, we use only two regions, i.e., Tokyo and Kyoto for training. To train with the full set, please download the OpenEarthMap dataset from https://zenodo.org/record/7223446. Note for xBD data preparation is available at https://github.com/bao18/open_earth_map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gn8aGxUvpBls",
    "outputId": "82f2abed-3597-4e31-abbf-a0c0c3d40804"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples            : 3501\n",
      "Training/Testing samples : 3000\n",
      "Validation samples       : 500\n"
     ]
    }
   ],
   "source": [
    "img_pths = [f for f in Path(OEM_DATA_DIR).rglob(\"*.tif\") if \"/labels/\" in str(f)]\n",
    "\n",
    "train_test_pths = [str(f) for f in img_pths if f.name in np.loadtxt(TRAIN_LIST, dtype=str)]\n",
    "val_pths = [str(f) for f in img_pths if f.name in np.loadtxt(VAL_LIST, dtype=str)]\n",
    "\n",
    "print(\"Total samples            :\", len(img_pths))\n",
    "print(\"Training/Testing samples :\", len(train_test_pths))\n",
    "print(\"Validation samples       :\", len(val_pths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training list contains 2500 elements.\n",
      "Testing list contains 500 elements.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(train_test_pths)\n",
    "\n",
    "training_pths = train_test_pths[:2500]\n",
    "testing_pths = train_test_pths[2500:]\n",
    "\n",
    "print(f\"Training list contains {len(training_pths)} elements.\")\n",
    "print(f\"Testing list contains {len(testing_pths)} elements.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-uFSOcgpBlt"
   },
   "source": [
    "### Define training and validation dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OpenEarthMap/aachen/labels/aachen_11.tif'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "DkjJGjCOpBlt"
   },
   "outputs": [],
   "source": [
    "trainset = source.dataset.Dataset(training_pths, classes=classes, size=512, train=True)\n",
    "validset = source.dataset.Dataset(val_pths, classes=classes, train=False)\n",
    "testset = source.dataset.Dataset(testing_pths, classes=classes, train=False)\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(validset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aR9cFGaspBlt"
   },
   "source": [
    "### Setup network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oTIQto7LpBlt",
    "outputId": "dceb44e7-4f97-4865-c153-aa65fe099f75"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Wrong encoder name `lsk_net`, supported encoders: ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'resnext50_32x4d', 'resnext101_32x4d', 'resnext101_32x8d', 'resnext101_32x16d', 'resnext101_32x32d', 'resnext101_32x48d', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn107', 'dpn131', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'inceptionresnetv2', 'inceptionv4', 'efficientnet-b0', 'efficientnet-b1', 'efficientnet-b2', 'efficientnet-b3', 'efficientnet-b4', 'efficientnet-b5', 'efficientnet-b6', 'efficientnet-b7', 'mobilenet_v2', 'xception', 'timm-efficientnet-b0', 'timm-efficientnet-b1', 'timm-efficientnet-b2', 'timm-efficientnet-b3', 'timm-efficientnet-b4', 'timm-efficientnet-b5', 'timm-efficientnet-b6', 'timm-efficientnet-b7', 'timm-efficientnet-b8', 'timm-efficientnet-l2', 'timm-tf_efficientnet_lite0', 'timm-tf_efficientnet_lite1', 'timm-tf_efficientnet_lite2', 'timm-tf_efficientnet_lite3', 'timm-tf_efficientnet_lite4', 'timm-resnest14d', 'timm-resnest26d', 'timm-resnest50d', 'timm-resnest101e', 'timm-resnest200e', 'timm-resnest269e', 'timm-resnest50d_4s2x40d', 'timm-resnest50d_1s4x24d', 'timm-res2net50_26w_4s', 'timm-res2net101_26w_4s', 'timm-res2net50_26w_6s', 'timm-res2net50_26w_8s', 'timm-res2net50_48w_2s', 'timm-res2net50_14w_8s', 'timm-res2next50', 'timm-regnetx_002', 'timm-regnetx_004', 'timm-regnetx_006', 'timm-regnetx_008', 'timm-regnetx_016', 'timm-regnetx_032', 'timm-regnetx_040', 'timm-regnetx_064', 'timm-regnetx_080', 'timm-regnetx_120', 'timm-regnetx_160', 'timm-regnetx_320', 'timm-regnety_002', 'timm-regnety_004', 'timm-regnety_006', 'timm-regnety_008', 'timm-regnety_016', 'timm-regnety_032', 'timm-regnety_040', 'timm-regnety_064', 'timm-regnety_080', 'timm-regnety_120', 'timm-regnety_160', 'timm-regnety_320', 'timm-skresnet18', 'timm-skresnet34', 'timm-skresnext50_32x4d', 'timm-mobilenetv3_large_075', 'timm-mobilenetv3_large_100', 'timm-mobilenetv3_large_minimal_100', 'timm-mobilenetv3_small_075', 'timm-mobilenetv3_small_100', 'timm-mobilenetv3_small_minimal_100', 'timm-gernet_s', 'timm-gernet_m', 'timm-gernet_l', 'mit_b0', 'mit_b1', 'mit_b2', 'mit_b3', 'mit_b4', 'mit_b5', 'mobileone_s0', 'mobileone_s1', 'mobileone_s2', 'mobileone_s3', 'mobileone_s4']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/segmentation_models_pytorch/encoders/__init__.py:65\u001b[0m, in \u001b[0;36mget_encoder\u001b[0;34m(name, in_channels, depth, weights, output_stride, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     Encoder \u001b[38;5;241m=\u001b[39m \u001b[43mencoders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'lsk_net'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m network \u001b[38;5;241m=\u001b[39m \u001b[43msmp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUnet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimagenet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlsk_net\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# count parameters\u001b[39;00m\n\u001b[1;32m     10\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/segmentation_models_pytorch/base/hub_mixin.py:147\u001b[0m, in \u001b[0;36msupports_config_loading.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    146\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m k\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)}\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/segmentation_models_pytorch/decoders/unet/model.py:76\u001b[0m, in \u001b[0;36mUnet.__init__\u001b[0;34m(self, encoder_name, encoder_depth, encoder_weights, decoder_use_batchnorm, decoder_channels, decoder_attention_type, in_channels, classes, activation, aux_params, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;129m@supports_config_loading\u001b[39m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m     73\u001b[0m ):\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m \u001b[43mget_encoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43min_channels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_depth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder \u001b[38;5;241m=\u001b[39m UnetDecoder(\n\u001b[1;32m     85\u001b[0m         encoder_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mout_channels,\n\u001b[1;32m     86\u001b[0m         decoder_channels\u001b[38;5;241m=\u001b[39mdecoder_channels,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m         attention_type\u001b[38;5;241m=\u001b[39mdecoder_attention_type,\n\u001b[1;32m     91\u001b[0m     )\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msegmentation_head \u001b[38;5;241m=\u001b[39m SegmentationHead(\n\u001b[1;32m     94\u001b[0m         in_channels\u001b[38;5;241m=\u001b[39mdecoder_channels[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     95\u001b[0m         out_channels\u001b[38;5;241m=\u001b[39mclasses,\n\u001b[1;32m     96\u001b[0m         activation\u001b[38;5;241m=\u001b[39mactivation,\n\u001b[1;32m     97\u001b[0m         kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     98\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/segmentation_models_pytorch/encoders/__init__.py:67\u001b[0m, in \u001b[0;36mget_encoder\u001b[0;34m(name, in_channels, depth, weights, output_stride, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     Encoder \u001b[38;5;241m=\u001b[39m encoders[name][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong encoder name `\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m`, supported encoders: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     69\u001b[0m             name, \u001b[38;5;28mlist\u001b[39m(encoders\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m     70\u001b[0m         )\n\u001b[1;32m     71\u001b[0m     )\n\u001b[1;32m     73\u001b[0m params \u001b[38;5;241m=\u001b[39m encoders[name][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     74\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(depth\u001b[38;5;241m=\u001b[39mdepth)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Wrong encoder name `lsk_net`, supported encoders: ['resnet18', 'resnet34', 'resnet50', 'resnet101', 'resnet152', 'resnext50_32x4d', 'resnext101_32x4d', 'resnext101_32x8d', 'resnext101_32x16d', 'resnext101_32x32d', 'resnext101_32x48d', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn107', 'dpn131', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'senet154', 'se_resnet50', 'se_resnet101', 'se_resnet152', 'se_resnext50_32x4d', 'se_resnext101_32x4d', 'densenet121', 'densenet169', 'densenet201', 'densenet161', 'inceptionresnetv2', 'inceptionv4', 'efficientnet-b0', 'efficientnet-b1', 'efficientnet-b2', 'efficientnet-b3', 'efficientnet-b4', 'efficientnet-b5', 'efficientnet-b6', 'efficientnet-b7', 'mobilenet_v2', 'xception', 'timm-efficientnet-b0', 'timm-efficientnet-b1', 'timm-efficientnet-b2', 'timm-efficientnet-b3', 'timm-efficientnet-b4', 'timm-efficientnet-b5', 'timm-efficientnet-b6', 'timm-efficientnet-b7', 'timm-efficientnet-b8', 'timm-efficientnet-l2', 'timm-tf_efficientnet_lite0', 'timm-tf_efficientnet_lite1', 'timm-tf_efficientnet_lite2', 'timm-tf_efficientnet_lite3', 'timm-tf_efficientnet_lite4', 'timm-resnest14d', 'timm-resnest26d', 'timm-resnest50d', 'timm-resnest101e', 'timm-resnest200e', 'timm-resnest269e', 'timm-resnest50d_4s2x40d', 'timm-resnest50d_1s4x24d', 'timm-res2net50_26w_4s', 'timm-res2net101_26w_4s', 'timm-res2net50_26w_6s', 'timm-res2net50_26w_8s', 'timm-res2net50_48w_2s', 'timm-res2net50_14w_8s', 'timm-res2next50', 'timm-regnetx_002', 'timm-regnetx_004', 'timm-regnetx_006', 'timm-regnetx_008', 'timm-regnetx_016', 'timm-regnetx_032', 'timm-regnetx_040', 'timm-regnetx_064', 'timm-regnetx_080', 'timm-regnetx_120', 'timm-regnetx_160', 'timm-regnetx_320', 'timm-regnety_002', 'timm-regnety_004', 'timm-regnety_006', 'timm-regnety_008', 'timm-regnety_016', 'timm-regnety_032', 'timm-regnety_040', 'timm-regnety_064', 'timm-regnety_080', 'timm-regnety_120', 'timm-regnety_160', 'timm-regnety_320', 'timm-skresnet18', 'timm-skresnet34', 'timm-skresnext50_32x4d', 'timm-mobilenetv3_large_075', 'timm-mobilenetv3_large_100', 'timm-mobilenetv3_large_minimal_100', 'timm-mobilenetv3_small_075', 'timm-mobilenetv3_small_100', 'timm-mobilenetv3_small_minimal_100', 'timm-gernet_s', 'timm-gernet_m', 'timm-gernet_l', 'mit_b0', 'mit_b1', 'mit_b2', 'mit_b3', 'mit_b4', 'mit_b5', 'mobileone_s0', 'mobileone_s1', 'mobileone_s2', 'mobileone_s3', 'mobileone_s4']\""
     ]
    }
   ],
   "source": [
    "network = smp.Unet(\n",
    "    classes=n_classes,\n",
    "    activation=None,\n",
    "    encoder_weights=\"imagenet\",\n",
    "    encoder_name=\"lsk_net\",\n",
    "    decoder_attention_type=\"scse\",\n",
    ")\n",
    "\n",
    "# count parameters\n",
    "params = 0\n",
    "for p in network.parameters():\n",
    "    if p.requires_grad:\n",
    "        params += p.numel()\n",
    "\n",
    "criterion = source.losses.CEWithLogitsLoss(weights=classes_wt)\n",
    "criterion_name = 'CE'\n",
    "metric = source.metrics.IoU2()\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=learning_rate)\n",
    "network_fout = f\"{network.name}_s{seed}_{criterion.name}\"\n",
    "OUT_DIR += network_fout # path to save prediction images\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Model output name  :\", network_fout)\n",
    "print(\"Number of parameters: \", params)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Number of GPUs :\", torch.cuda.device_count())\n",
    "    network = torch.nn.DataParallel(network)\n",
    "    optimizer = torch.optim.Adam(\n",
    "        [dict(params=network.module.parameters(), lr=learning_rate)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2lQx068bQwo"
   },
   "source": [
    "### Visualization functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "yTJFfnmspBlu"
   },
   "outputs": [],
   "source": [
    "class_rgb = {\n",
    "    \"Bareland\": [128, 0, 0],\n",
    "    \"Grass\": [0, 255, 36],\n",
    "    \"Pavement\": [148, 148, 148],\n",
    "    \"Road\": [255, 255, 255],\n",
    "    \"Tree\": [34, 97, 38],\n",
    "    \"Water\": [0, 69, 255],\n",
    "    \"Cropland\": [75, 181, 73],\n",
    "    \"buildings\": [222, 31, 7],\n",
    "}\n",
    "\n",
    "class_gray = {\n",
    "    \"Bareland\": 1,\n",
    "    \"Grass\": 2,\n",
    "    \"Pavement\": 3,\n",
    "    \"Road\": 4,\n",
    "    \"Tree\": 5,\n",
    "    \"Water\": 6,\n",
    "    \"Cropland\": 7,\n",
    "    \"buildings\": 8,\n",
    "}\n",
    "\n",
    "def label2rgb(a):\n",
    "    \"\"\"\n",
    "    a: labels (HxW)\n",
    "    \"\"\"\n",
    "    out = np.zeros(shape=a.shape + (3,), dtype=\"uint8\")\n",
    "    for k, v in class_gray.items():\n",
    "        out[a == v, 0] = class_rgb[k][0]\n",
    "        out[a == v, 1] = class_rgb[k][1]\n",
    "        out[a == v, 2] = class_rgb[k][2]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hn9_yGisbYAN"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1t5R7gDKpBlu",
    "outputId": "6a0789b0-3d62-47fa-953d-1b700d006045"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 750/750 [47:28<00:00,  3.80s/it, CELoss=1.54, mIoU=0.244] \n",
      "Valid: 100%|██████████| 125/125 [12:15<00:00,  5.88s/it, CELoss=1.11, mIoU=0.337]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n",
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 750/750 [46:12<00:00,  3.70s/it, CELoss=1.14, mIoU=0.369]\n",
      "Valid: 100%|██████████| 125/125 [09:11<00:00,  4.41s/it, CELoss=0.912, mIoU=0.393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n",
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 750/750 [45:46<00:00,  3.66s/it, CELoss=1.01, mIoU=0.4]  \n",
      "Valid: 100%|██████████| 125/125 [08:46<00:00,  4.21s/it, CELoss=0.836, mIoU=0.411]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n",
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 750/750 [47:03<00:00,  3.76s/it, CELoss=0.919, mIoU=0.425]\n",
      "Valid: 100%|██████████| 125/125 [09:02<00:00,  4.34s/it, CELoss=0.815, mIoU=0.447]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n",
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 750/750 [45:57<00:00,  3.68s/it, CELoss=0.863, mIoU=0.462]\n",
      "Valid: 100%|██████████| 125/125 [09:14<00:00,  4.43s/it, CELoss=0.772, mIoU=0.466]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved!\n",
      "Processing time: 16860.144696712494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "max_score = 0\n",
    "train_hist = []\n",
    "valid_hist = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "  print(f\"\\nEpoch: {epoch + 1}\")\n",
    "\n",
    "  logs_train = source.runner.train_epoch(\n",
    "      model=network,\n",
    "      optimizer=optimizer,\n",
    "      criterion=criterion,\n",
    "      metric=metric,\n",
    "      dataloader=train_loader,\n",
    "      device=device,\n",
    "  )\n",
    "\n",
    "  logs_valid = source.runner.valid_epoch(\n",
    "      model=network,\n",
    "      criterion=criterion,\n",
    "      metric=metric,\n",
    "      dataloader=valid_loader,\n",
    "      device=device,\n",
    "  )\n",
    "\n",
    "  train_hist.append(logs_train)\n",
    "  valid_hist.append(logs_valid)\n",
    "\n",
    "  score = logs_valid[metric.name]\n",
    "\n",
    "  if max_score < score:\n",
    "      max_score = score\n",
    "      torch.save(network.state_dict(), os.path.join(WEIGHT_DIR, f\"{network_fout}.pth\"))\n",
    "      print(\"Model saved!\")\n",
    "\n",
    "end = time.time()\n",
    "print('Processing time:',end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONWiNQMWAHP4"
   },
   "source": [
    "### Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "def zip_files(output_dir, zip_filename):\n",
    "    with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
    "        for root, _, files in os.walk(output_dir):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                zipf.write(file_path, os.path.relpath(file_path, output_dir))\n",
    "                os.remove(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load network\n",
    "network.load_state_dict(torch.load(os.path.join(WEIGHT_DIR, f\"{network_fout}.pth\")))\n",
    "network.to(device).eval()\n",
    "\n",
    "for fn_img in testing_pths:\n",
    "  fn_img = fn_img.replace(\"/labels/\", \"/images/\")\n",
    "  img = source.dataset.load_multiband(fn_img)\n",
    "  h, w = img.shape[:2]\n",
    "  power = math.ceil(np.log2(h) / np.log2(2))\n",
    "  shape = (2 ** power, 2 ** power)\n",
    "  img = cv2.resize(img, shape)\n",
    "\n",
    "  # test time augmentation\n",
    "  imgs = []\n",
    "  imgs.append(img.copy())\n",
    "  imgs.append(img[:, ::-1, :].copy())\n",
    "  imgs.append(img[::-1, :, :].copy())\n",
    "  imgs.append(img[::-1, ::-1, :].copy())\n",
    "\n",
    "  input = torch.cat([TF.to_tensor(x).unsqueeze(0) for x in imgs], dim=0).float().to(device)\n",
    "\n",
    "  pred = []\n",
    "  with torch.no_grad():\n",
    "      msk = network(input)\n",
    "      msk = torch.softmax(msk[:, :, ...], dim=1)\n",
    "      msk = msk.cpu().numpy()\n",
    "      pred = (msk[0, :, :, :] + msk[1, :, :, ::-1] + msk[2, :, ::-1, :] + msk[3, :, ::-1, ::-1])/4\n",
    "  pred = pred.argmax(axis=0).astype(\"uint8\")\n",
    "  size = pred.shape[0:]\n",
    "  y_pr = cv2.resize(pred, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "  # save image as png\n",
    "  filename = os.path.splitext(os.path.basename(fn_img))[0]\n",
    "  Image.fromarray(y_pr).save(os.path.join(OUT_DIR, filename+'.tif'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred processing .ipynb_checkpoints: [Errno 21] Is a directory: '/home/jovyan/open-earth-map/test/labels/.ipynb_checkpoints'. Skipping.\n",
      "Dataset mIoU: 0.26474113901459717\n",
      "mIoU per image:\n",
      "- aachen_4.tif: 0.26405045335720734\n",
      "- aachen_5.tif: 0.29852855377949916\n",
      "- aachen_1.tif: 0.312184203275812\n",
      "- aachen_2.tif: 0.24481229375161148\n",
      "- aachen_6.tif: 0.20413019090885565\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def calculate_iou(gt_mask, pred_mask, num_classes):\n",
    "    \"\"\"Calculates Intersection over Union (IoU) for each class.\n",
    "\n",
    "    Args:\n",
    "        gt_mask: Ground truth segmentation mask (NumPy array).\n",
    "        pred_mask: Predicted segmentation mask (NumPy array).\n",
    "        num_classes: Number of classes.\n",
    "\n",
    "    Returns:\n",
    "        A NumPy array containing IoU for each class.\n",
    "    \"\"\"\n",
    "\n",
    "    iou_per_class = np.zeros(num_classes)\n",
    "    for class_id in range(num_classes):\n",
    "        intersection = np.sum((gt_mask == class_id) & (pred_mask == class_id))\n",
    "        union = np.sum((gt_mask == class_id) | (pred_mask == class_id))\n",
    "\n",
    "        if union == 0:  # Handle cases where the union is zero (prevent division by zero)\n",
    "            iou_per_class[class_id] = 0.0  # Or np.nan if you prefer\n",
    "        else:\n",
    "            iou_per_class[class_id] = intersection / union\n",
    "\n",
    "    return iou_per_class\n",
    "\n",
    "\n",
    "def calculate_miou(gt_mask, pred_mask, num_classes):\n",
    "    \"\"\"Calculates mean Intersection over Union (mIoU).\n",
    "\n",
    "    Args:\n",
    "        gt_mask: Ground truth segmentation mask (NumPy array).\n",
    "        pred_mask: Predicted segmentation mask (NumPy array).\n",
    "        num_classes: Number of classes.\n",
    "\n",
    "    Returns:\n",
    "        The mIoU score.\n",
    "    \"\"\"\n",
    "    iou_per_class = calculate_iou(gt_mask, pred_mask, num_classes)\n",
    "    miou = np.nanmean(iou_per_class) #Handle nan values that could arise from classes not present\n",
    "\n",
    "    return miou\n",
    "\n",
    "\n",
    "def load_mask(image_path):\n",
    "    \"\"\"Loads a segmentation mask from an image file.\n",
    "\n",
    "    Args:\n",
    "        image_path: Path to the image file.\n",
    "\n",
    "    Returns:\n",
    "        A NumPy array representing the mask.\n",
    "    \"\"\"\n",
    "    mask = Image.open(image_path)\n",
    "    mask = np.array(mask)\n",
    "    return mask\n",
    "\n",
    "def calculate_miou_for_dataset(gt_dir, pred_dir, num_classes):\n",
    "    \"\"\"Calculates mIoU over a dataset of images.\n",
    "\n",
    "    Args:\n",
    "        gt_dir: Path to the directory containing ground truth masks.\n",
    "        pred_dir: Path to the directory containing predicted masks.\n",
    "        num_classes: Number of classes.\n",
    "\n",
    "    Returns:\n",
    "        The mean mIoU over the dataset.\n",
    "        A dictionary containing the mIoU for each image.\n",
    "    \"\"\"\n",
    "\n",
    "    image_names = set(os.listdir(gt_dir)) & set(os.listdir(pred_dir)) #Find common file names\n",
    "    miou_scores = []\n",
    "    image_miou_dict = {}\n",
    "\n",
    "    if not image_names:\n",
    "        raise ValueError(\"No matching files found in the ground truth and prediction directories.\")\n",
    "\n",
    "    for image_name in image_names:\n",
    "        gt_path = os.path.join(gt_dir, image_name)\n",
    "        pred_path = os.path.join(pred_dir, image_name)\n",
    "\n",
    "        try:\n",
    "            gt_mask = load_mask(gt_path)\n",
    "            pred_mask = load_mask(pred_path)\n",
    "\n",
    "            if gt_mask.shape != pred_mask.shape:\n",
    "                print(f\"Warning: Masks for {image_name} have different shapes. Skipping.\")\n",
    "                continue #skip this image\n",
    "\n",
    "            miou = calculate_miou(gt_mask, pred_mask, num_classes)\n",
    "            miou_scores.append(miou)\n",
    "            image_miou_dict[image_name] = miou\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: File not found: {image_name}. Skipping.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred processing {image_name}: {e}. Skipping.\")\n",
    "\n",
    "    if not miou_scores: #if no valid images were processed\n",
    "      return 0.0, {}\n",
    "\n",
    "    dataset_miou = np.mean(miou_scores)\n",
    "    return dataset_miou, image_miou_dict\n",
    "\n",
    "# Example paths (replace with your actual paths)\n",
    "gt_dir = \"test/labels\"  # Directory containing multiple GT masks\n",
    "pred_dir = OUT_DIR    # Directory containing multiple predicted masks\n",
    "num_classes = 8\n",
    "\n",
    "try:\n",
    "    dataset_miou, image_miou_dict = calculate_miou_for_dataset(gt_dir, pred_dir, num_classes)\n",
    "\n",
    "    print(f\"Dataset mIoU: {dataset_miou}\")\n",
    "\n",
    "    if image_miou_dict: #Print individual miou only if dictionary is not empty\n",
    "      print(\"mIoU per image:\")\n",
    "      for image_name, miou in image_miou_dict.items():\n",
    "          print(f\"- {image_name}: {miou}\")\n",
    "\n",
    "except ValueError as e:\n",
    "    print(f\"ValueError: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3I0hKRyHMl3"
   },
   "source": [
    "### Testing a model for a large Geotiff image\n",
    "\n",
    "A sample image is provided by the Geospatial Information Authority of Japan at https://cyberjapandata.gsi.go.jp/xyz/seamlessphoto/{z}/{x}/{y}.jpg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WguTdAFqHWAe",
    "outputId": "f33e8f67-8953-4fca-bc11-11b670003234"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'network' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# load network\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mnetwork\u001b[49m\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(WEIGHT_DIR, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnetwork_fout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[1;32m      5\u001b[0m network\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      7\u001b[0m test_large \u001b[38;5;241m=\u001b[39m TEST_DIR\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m35_1_op_2023.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'network' is not defined"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# load network\n",
    "network.load_state_dict(torch.load(os.path.join(WEIGHT_DIR, f\"{network_fout}.pth\")))\n",
    "network.to(device).eval()\n",
    "\n",
    "test_large = TEST_DIR+\"35_1_op_2023.jpg\"\n",
    "\n",
    "# process large Geotiff image\n",
    "img0 = source.dataset.load_multiband(test_large)\n",
    "\n",
    "# get crs and transform\n",
    "crs, trans = source.dataset.get_crs(test_large)\n",
    "\n",
    "if img0.shape[2] > 3:\n",
    "    img0 = img0[:, :, :3]\n",
    "width = img0.shape[1]\n",
    "band = img0.shape[2]\n",
    "\n",
    "patch_size = 512\n",
    "stride = 256\n",
    "C = int(np.ceil( (width - patch_size) / stride ) + 1)\n",
    "R = int(np.ceil( (height - patch_size) / stride ) + 1)\n",
    "\n",
    "# weight matrix B for avoiding boundaries of patches\n",
    "if patch_size > stride:\n",
    "    w = patch_size\n",
    "    s1 = stride\n",
    "    s2 = w - s1\n",
    "    d = 1/(1+s2)\n",
    "    B1 = np.ones((w,w))\n",
    "    B1[:,s1::] = np.dot(np.ones((w,1)),(-np.arange(1,s2+1)*d+1).reshape(1,s2))\n",
    "    B2 = np.flip(B1)\n",
    "    B3 = B1.T\n",
    "    B4 = np.flip(B3)\n",
    "    B = B1*B2*B3*B4\n",
    "else:\n",
    "    B = np.ones((w,w))\n",
    "\n",
    "img1 = np.zeros((patch_size+stride*(R-1), patch_size+stride*(C-1),3))\n",
    "img1[0:height,0:width,:] = img0.copy()\n",
    "\n",
    "pred_all = np.zeros((9,patch_size+stride*(R-1), patch_size+stride*(C-1)))\n",
    "weight = np.zeros((patch_size+stride*(R-1), patch_size+stride*(C-1)))\n",
    "\n",
    "for r in range(R):\n",
    "    for c in range(C):\n",
    "        img = img1[r*stride:r*stride+patch_size,c*stride:c*stride+patch_size,:].copy().astype(np.float32)/255\n",
    "        imgs = []\n",
    "        imgs.append(img.copy())\n",
    "        imgs.append(img[:, ::-1, :].copy())\n",
    "        imgs.append(img[::-1, :, :].copy())\n",
    "        imgs.append(img[::-1, ::-1, :].copy())\n",
    "\n",
    "        input = torch.cat([TF.to_tensor(x).unsqueeze(0) for x in imgs], dim=0).float().to(device)\n",
    "\n",
    "        pred = []\n",
    "        with torch.no_grad():\n",
    "            msk = network(input)\n",
    "            msk = torch.softmax(msk[:, :, ...], dim=1)\n",
    "            msk = msk.cpu().numpy()\n",
    "\n",
    "            pred = (msk[0, :, :, :] + msk[1, :, :, ::-1] + msk[2, :, ::-1, :] + msk[3, :, ::-1, ::-1])/4\n",
    "\n",
    "        pred_all[:,r*stride:r*stride+patch_size,c*stride:c*stride+patch_size] += pred.copy()*B\n",
    "        weight[r*stride:r*stride+patch_size,c*stride:c*stride+patch_size] += B\n",
    "\n",
    "for b in range(9):\n",
    "    pred_all[b,:,:] = pred_all[b,:,:]/weight\n",
    "    if b == 0:\n",
    "        pred_all[b,:,:] = 0\n",
    "\n",
    "pred_all = pred_all.argmax(axis=0).astype(\"uint8\")\n",
    "\n",
    "filename = os.path.splitext(os.path.basename(test_large))[0]\n",
    "pr_rgb = label2rgb(pred_all)\n",
    "Image.fromarray(pr_rgb[0:height,0:width,:]).save(os.path.join(OUT_DIR, filename+'_pr.png'))\n",
    "\n",
    "# save geotiff\n",
    "pr_rgb = np.transpose(pr_rgb[0:height,0:width,:], (2,0,1))\n",
    "source.dataset.save_img(os.path.join(OUT_DIR, filename+'_pr.tif'),pr_rgb,crs,trans)\n",
    "\n",
    "end = time.time()\n",
    "print('Processing time:',end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing patch  0 \n",
      "\n",
      "processing patch  8 \n",
      "\n",
      "processing patch  16 \n",
      "\n",
      "processing patch  24 \n",
      "\n",
      "processing patch  32 \n",
      "\n",
      "processing patch  40 \n",
      "\n",
      "processing patch  48 \n",
      "\n",
      "processing patch  56 \n",
      "\n",
      "processing patch  64 \n",
      "\n",
      "processing patch  72 \n",
      "\n",
      "processing patch  80 \n",
      "\n",
      "processing patch  88 \n",
      "\n",
      "processing patch  96 \n",
      "\n",
      "processing patch  104 \n",
      "\n",
      "processing patch  112 \n",
      "\n",
      "processing patch  120 \n",
      "\n",
      "processing patch  128 \n",
      "\n",
      "processing patch  136 \n",
      "\n",
      "processing patch  144 \n",
      "\n",
      "processing patch  152 \n",
      "\n",
      "processing patch  160 \n",
      "\n",
      "processing patch  168 \n",
      "\n",
      "processing patch  176 \n",
      "\n",
      "processing patch  184 \n",
      "\n",
      "processing patch  192 \n",
      "\n",
      "processing patch  200 \n",
      "\n",
      "processing patch  208 \n",
      "\n",
      "processing patch  216 \n",
      "\n",
      "processing patch  224 \n",
      "\n",
      "processing patch  232 \n",
      "\n",
      "processing patch  240 \n",
      "\n",
      "processing patch  248 \n",
      "\n",
      "processing patch  256 \n",
      "\n",
      "processing patch  264 \n",
      "\n",
      "processing patch  272 \n",
      "\n",
      "processing patch  280 \n",
      "\n",
      "processing patch  288 \n",
      "\n",
      "processing patch  296 \n",
      "\n",
      "processing patch  304 \n",
      "\n",
      "processing patch  312 \n",
      "\n",
      "processing patch  320 \n",
      "\n",
      "processing patch  328 \n",
      "\n",
      "processing patch  336 \n",
      "\n",
      "processing patch  344 \n",
      "\n",
      "processing patch  352 \n",
      "\n",
      "processing patch  360 \n",
      "\n",
      "processing patch  368 \n",
      "\n",
      "processing patch  376 \n",
      "\n",
      "processing patch  384 \n",
      "\n",
      "processing patch  392 \n",
      "\n",
      "processing patch  400 \n",
      "\n",
      "processing patch  408 \n",
      "\n",
      "processing patch  416 \n",
      "\n",
      "processing patch  424 \n",
      "\n",
      "processing patch  432 \n",
      "\n",
      "processing patch  440 \n",
      "\n",
      "processing patch  448 \n",
      "\n",
      "processing patch  456 \n",
      "\n",
      "processing patch  464 \n",
      "\n",
      "processing patch  472 \n",
      "\n",
      "processing patch  480 \n",
      "\n",
      "processing patch  488 \n",
      "\n",
      "processing patch  496 \n",
      "\n",
      "processing patch  504 \n",
      "\n",
      "processing patch  512 \n",
      "\n",
      "processing patch  520 \n",
      "\n",
      "processing patch  528 \n",
      "\n",
      "processing patch  536 \n",
      "\n",
      "processing patch  544 \n",
      "\n",
      "processing patch  552 \n",
      "\n",
      "processing patch  560 \n",
      "\n",
      "processing patch  568 \n",
      "\n",
      "processing patch  576 \n",
      "\n",
      "processing patch  584 \n",
      "\n",
      "processing patch  592 \n",
      "\n",
      "processing patch  600 \n",
      "\n",
      "processing patch  608 \n",
      "\n",
      "processing patch  616 \n",
      "\n",
      "processing patch  624 \n",
      "\n",
      "processing patch  632 \n",
      "\n",
      "processing patch  640 \n",
      "\n",
      "processing patch  648 \n",
      "\n",
      "processing patch  656 \n",
      "\n",
      "processing patch  664 \n",
      "\n",
      "processing patch  672 \n",
      "\n",
      "processing patch  680 \n",
      "\n",
      "processing patch  688 \n",
      "\n",
      "processing patch  696 \n",
      "\n",
      "processing patch  704 \n",
      "\n",
      "processing patch  712 \n",
      "\n",
      "processing patch  720 \n",
      "\n",
      "processing patch  728 \n",
      "\n",
      "processing patch  736 \n",
      "\n",
      "processing patch  744 \n",
      "\n",
      "processing patch  752 \n",
      "\n",
      "processing patch  760 \n",
      "\n",
      "processing patch  768 \n",
      "\n",
      "processing patch  776 \n",
      "\n",
      "processing patch  784 \n",
      "\n",
      "processing patch  792 \n",
      "\n",
      "processing patch  800 \n",
      "\n",
      "processing patch  808 \n",
      "\n",
      "processing patch  816 \n",
      "\n",
      "processing patch  824 \n",
      "\n",
      "processing patch  832 \n",
      "\n",
      "processing patch  840 \n",
      "\n",
      "processing patch  848 \n",
      "\n",
      "processing patch  856 \n",
      "\n",
      "processing patch  864 \n",
      "\n",
      "processing patch  872 \n",
      "\n",
      "processing patch  880 \n",
      "\n",
      "processing patch  888 \n",
      "\n",
      "processing patch  896 \n",
      "\n",
      "processing patch  904 \n",
      "\n",
      "processing patch  912 \n",
      "\n",
      "processing patch  920 \n",
      "\n",
      "processing patch  928 \n",
      "\n",
      "processing patch  936 \n",
      "\n",
      "processing patch  944 \n",
      "\n",
      "processing patch  952 \n",
      "\n",
      "processing patch  960 \n",
      "\n",
      "processing patch  968 \n",
      "\n",
      "processing patch  976 \n",
      "\n",
      "processing patch  984 \n",
      "\n",
      "processing patch  992 \n",
      "\n",
      "processing patch  1000 \n",
      "\n",
      "processing patch  1008 \n",
      "\n",
      "processing patch  1016 \n",
      "\n",
      "processing patch  1024 \n",
      "\n",
      "processing patch  1032 \n",
      "\n",
      "processing patch  1040 \n",
      "\n",
      "processing patch  1048 \n",
      "\n",
      "processing patch  1056 \n",
      "\n",
      "processing patch  1064 \n",
      "\n",
      "processing patch  1072 \n",
      "\n",
      "processing patch  1080 \n",
      "\n",
      "processing patch  1088 \n",
      "\n",
      "Processing time: 740.0337600708008\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Load network\n",
    "network.load_state_dict(torch.load(os.path.join(WEIGHT_DIR, f\"{network_fout}.pth\")))\n",
    "network.to(device).eval()\n",
    "\n",
    "# Load large GeoTIFF image and metadata\n",
    "test_large = TEST_DIR + \"35_1_op_2023.jpg\"\n",
    "img0 = source.dataset.load_multiband(test_large)\n",
    "crs, trans = source.dataset.get_crs(test_large)\n",
    "\n",
    "# Ensure 3-band (RGB) data\n",
    "if img0.shape[2] > 3:\n",
    "    img0 = img0[:, :, :3]\n",
    "\n",
    "height, width, _ = img0.shape\n",
    "patch_size = 512\n",
    "\n",
    "# Padding image to ensure even division into patches\n",
    "pad_h = (patch_size - height % patch_size) % patch_size\n",
    "pad_w = (patch_size - width % patch_size) % patch_size\n",
    "img_padded = np.pad(img0, ((0, pad_h), (0, pad_w), (0, 0)), mode='reflect')\n",
    "\n",
    "# Prepare output arrays\n",
    "pred_all = np.zeros((9, height + pad_h, width + pad_w), dtype=np.float32)\n",
    "\n",
    "# Divide into non-overlapping patches\n",
    "patches = [\n",
    "    img_padded[r:r+patch_size, c:c+patch_size].astype(np.float32) / 255\n",
    "    for r in range(0, img_padded.shape[0], patch_size)\n",
    "    for c in range(0, img_padded.shape[1], patch_size)\n",
    "]\n",
    "\n",
    "# Batch process patches\n",
    "batch_size = 8  # Adjust based on GPU memory\n",
    "for i in range(0, len(patches), batch_size):\n",
    "    print(\"processing patch \", i, \"\\n\")\n",
    "    batch_patches = patches[i:i+batch_size]\n",
    "    \n",
    "    # Test time augmentation\n",
    "    augmented_patches = []\n",
    "    for img in batch_patches:\n",
    "        augmented_patches.extend([\n",
    "            img.copy(),  # Original\n",
    "            img[:, ::-1, :].copy(),  # Flip horizontally\n",
    "            img[::-1, :, :].copy(),  # Flip vertically\n",
    "            img[::-1, ::-1, :].copy()  # Flip both axes\n",
    "        ])\n",
    "    \n",
    "    input_tensor = torch.cat([TF.to_tensor(x).unsqueeze(0) for x in augmented_patches], dim=0).float().to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        msk = network(input_tensor)\n",
    "        msk = torch.softmax(msk, dim=1).cpu().numpy()\n",
    "    \n",
    "    # Aggregate predictions\n",
    "    for idx, img in enumerate(batch_patches):\n",
    "        r, c = divmod(i + idx, img_padded.shape[1] // patch_size)\n",
    "        pred = (\n",
    "            msk[idx*4] +\n",
    "            msk[idx*4+1][:, :, ::-1] +\n",
    "            msk[idx*4+2][:, ::-1, :] +\n",
    "            msk[idx*4+3][:, ::-1, ::-1]\n",
    "        ) / 4\n",
    "        \n",
    "        pred_all[:, r*patch_size:(r+1)*patch_size, c*patch_size:(c+1)*patch_size] = pred\n",
    "\n",
    "# Finalize predictions\n",
    "pred_all = pred_all.argmax(axis=0).astype(\"uint8\")[:height, :width]\n",
    "\n",
    "# Save outputs\n",
    "filename = os.path.splitext(os.path.basename(test_large))[0]\n",
    "pr_rgb = label2rgb(pred_all)\n",
    "Image.fromarray(pr_rgb).save(os.path.join(OUT_DIR, filename + '_pr.png'))\n",
    "\n",
    "# Save GeoTIFF\n",
    "# pr_rgb = np.transpose(pr_rgb, (2, 0, 1))\n",
    "# source.dataset.save_img(os.path.join(OUT_DIR, filename + '_pr.tif'), pr_rgb, crs, trans)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Processing time:\", end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "b8adc929056e836a7a3b0e312c82a4cd60bdf00e8c79486eca7d6ecc652c519a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
